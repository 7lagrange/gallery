{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__* This notebook is still working-in-progress, not everything works, expect an update from BentoML team soon__\n",
    "\n",
    "\n",
    "# BentoML Example: H2O Loan Default Prediction\n",
    "\n",
    "[BentoML](http://bentoml.ai) is an open source platform for machine learning model serving and deployment. \n",
    "\n",
    "This notebook demonstrates how to use BentoML to __turn a H2O model into a docker image containing a REST API server__ serving this model, as well as distributing your model as a command line tool or a pip-installable PyPI package.\n",
    "\n",
    "The notebook was built based on: https://github.com/kguruswamy/H2O3-Driverless-AI-Code-Examples/blob/master/Lending%20Club%20Data%20-%20H2O3%20Auto%20ML%20-%20Python%20Tutorial.ipynb\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=h2o&ea=h2o-loan-default-prediction&dt=h2o-loan-default-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bentoml\n",
    "!pip install h2o xlrd sklearn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "import bentoml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import math\n",
    "from sklearn import model_selection\n",
    "\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download training dataset\n",
    "if [ ! -f ./LoanStats3c.csv.zip ]; then\n",
    "    curl -O https://resources.lendingclub.com/LoanStats3c.csv.zip\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('expand_frame_repr', True)\n",
    "pd.set_option('max_colwidth',9999)\n",
    "pd.set_option('display.max_columns',9999)\n",
    "pd.set_option('display.max_rows',9999)\n",
    "\n",
    "data_dictionary = pd.read_excel(\"https://resources.lendingclub.com/LCDataDictionary.xlsx\")\n",
    "data_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very first row has non-header data and hence skipping it. Read to a data frame\n",
    "# Fix the Mon-Year on one column to be readable\n",
    "\n",
    "def parse_dates(x):\n",
    "    return datetime.strptime(x, \"%b-%d\")\n",
    "\n",
    "lc = pd.read_csv(\"LoanStats3c.csv.zip\", skiprows=1,verbose=False, parse_dates=['issue_d'],low_memory=False) \n",
    "lc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.loan_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep just \"Fully Paid\" and \"Charged Off\" to make it a simple 'Yes' or 'No' - binary classification problem\n",
    "\n",
    "lc = lc[lc.loan_status.isin(['Fully Paid','Charged Off'])]\n",
    "lc.loan_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns from the data frame that are Target Leakage ones\n",
    "# Target Leakage columns are generally created in hindsight by analysts/data engineers/operations after an outcome \n",
    "# was detected in historical data. If we don't remove them now, they would climb to the top of the feature list after a model is built and \n",
    "# falsely increase the accuracy to 95% :) \n",
    "#\n",
    "# In Production or real life scoring environment, don't expect these columns to be available at scoring time\n",
    "# , that is,when someone applies for a loan. So we don't train on those columns ...\n",
    "\n",
    "ignored_cols = [ \n",
    "                'out_prncp',                 # Remaining outstanding principal for total amount funded\n",
    "                'out_prncp_inv',             # Remaining outstanding principal for portion of total amount \n",
    "                                             # funded by investors\n",
    "                'total_pymnt',               # Payments received to date for total amount funded\n",
    "                'total_pymnt_inv',           # Payments received to date for portion of total amount \n",
    "                                             # funded by investors\n",
    "                'total_rec_prncp',           # Principal received to date \n",
    "                'total_rec_int',             # Interest received to date\n",
    "                'total_rec_late_fee',        # Late fees received to date\n",
    "                'recoveries',                # post charge off gross recovery\n",
    "                'collection_recovery_fee',   # post charge off collection fee\n",
    "                'last_pymnt_d',              # Last month payment was received\n",
    "                'last_pymnt_amnt',           # Last total payment amount received\n",
    "                'next_pymnt_d',              # Next scheduled payment date\n",
    "                'last_credit_pull_d',        # The most recent month LC pulled credit for this loan\n",
    "                'settlement_term',           # The number of months that the borrower will be on the settlement plan\n",
    "                'settlement_date',           # The date that the borrower agrees to the settlement plan\n",
    "                'settlement_amount',         # The loan amount that the borrower has agreed to settle for\n",
    "                'settlement_percentage',     # The settlement amount as a percentage of the payoff balance amount on the loan\n",
    "                'settlement_status',         # The status of the borrowerâ€™s settlement plan. Possible values are: \n",
    "                                             # COMPLETE, ACTIVE, BROKEN, CANCELLED, DENIED, DRAF\n",
    "                'debt_settlement_flag',      # Flags whether or not the borrower, who has charged-off, is working with \n",
    "                                             # a debt-settlement company.\n",
    "                'debt_settlement_flag_date'  # The most recent date that the Debt_Settlement_Flag has been set\n",
    "                ]\n",
    "\n",
    "lc = lc.drop(columns=ignored_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After dropping Target Leakage columns, we have 223K rows and 125 columns\n",
    "lc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os \n",
    "\n",
    "train_path = os.getcwd() + \"/train_lc.csv.zip\"\n",
    "test_path = os.getcwd() + \"/test_lc.csv.zip\"\n",
    "\n",
    "train_lc, test_lc = model_selection.train_test_split(lc, test_size=0.2, random_state=10,stratify=lc['loan_status'])\n",
    "train_lc.to_csv(train_path, index=False,compression=\"zip\")\n",
    "test_lc.to_csv(test_path, index=False,compression=\"zip\")\n",
    "\n",
    "# These two CSV files were created in the previous section\n",
    "train_path = os.getcwd()+\"/train_lc.csv.zip\"\n",
    "test_path = os.getcwd()+ \"/test_lc.csv.zip\"\n",
    "\n",
    "train = h2o.load_dataset(train_path)\n",
    "test = h2o.load_dataset(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# Identify predictors and response\n",
    "x = train.columns\n",
    "y = \"loan_status\"\n",
    "x.remove(y)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()\n",
    "\n",
    "# Run AutoML \n",
    "aml = H2OAutoML(project_name='LC', \n",
    "                max_models=10,         # 10 base models *FOR DEMO PURPOSE\n",
    "                balance_classes=True,  # Doing smart Class imbalance sampling\n",
    "                max_runtime_secs=60,   # 1 Minute *FOR DEMO PURPOSE\n",
    "                seed=1234)             # Set a seed for reproducability\n",
    "aml.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the AutoML Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pc = aml.predict(test)\n",
    "test_pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define BentoService for model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile loan_prediction.py\n",
    "\n",
    "import h2o\n",
    "\n",
    "from bentoml import api, env, artifacts, BentoService\n",
    "from bentoml.artifact import H2oModelArtifact\n",
    "from bentoml.handlers import DataframeHandler\n",
    "\n",
    "@env(pip_dependencies = ['h2o', 'pandas'])\n",
    "@artifacts([H2oModelArtifact('model')])\n",
    "class LoanPrediction(BentoService):\n",
    "    \n",
    "    @api(DataframeHandler)\n",
    "    def predict(self, df):\n",
    "        h2o_frame = h2o.H2OFrame(df, na_strings=['NaN'])\n",
    "        predictions = self.artifacts.model.predict(h2o_frame)\n",
    "        return predictions.as_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save BentoService to file archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1) import the custom BentoService defined above\n",
    "from loan_prediction import LoanPrediction\n",
    "\n",
    "# 2) `pack` it with required artifacts\n",
    "bentoml_svc = LoanPrediction.pack(model=aml.leader)\n",
    "\n",
    "# 3) save your BentoSerivce\n",
    "saved_path = bentoml_svc.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BentoService from archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_bentoml_svc = bentoml.load(saved_path)\n",
    "\n",
    "print(loaded_bentoml_svc.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Model Serving via REST API\n",
    "\n",
    "In your termnial, run the following command to start the REST API server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve {saved_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open http://127.0.0.1:5000 to see more information about the REST APIs server in your\n",
    "browser."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
