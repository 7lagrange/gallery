{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BentoML Example:  Keras Text Classification\n",
    "\n",
    "[BentoML](http://bentoml.ai) is an open source platform for machine learning model serving and deployment. \n",
    "\n",
    "This notebook demonstrates how to use BentoML to turn a Keras model into a docker image containing a REST API server serving this model, how to use your ML service built with BentoML as a CLI tool, and how to distribute it a pypi package.\n",
    "\n",
    "This notebook is built based on Keras's IMDB LSTM tutorial [here](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py).\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=keras&ea=keras-text-classification&dt=keras-text-classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bentoml\n",
    "!pip install tensorflow\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.13.1\n",
      "BentoML Version: 0.4.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow Version: %s\" % tf.__version__)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "import bentoml\n",
    "print(\"BentoML Version: %s\" % bentoml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000\n",
    "maxlen = 80 # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 300\n",
    "index_from=3 # word index offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iAsKG535pHep"
   },
   "source": [
    "# Prepare Dataset\n",
    "Download the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary mapping words to an integer index\n",
    "imdb.load_data(num_words=max_features)\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# The first indices are reserved\n",
    "word_index = {k:(v+index_from) for k,v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "\n",
    "# Use decode_review to look at original review text in training/testing data\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "def decode_review(encoded_text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in encoded_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features, index_from=index_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train,\n",
    "                                 value=word_index[\"<PAD>\"],\n",
    "                                 padding='post',\n",
    "                                 maxlen=maxlen)\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test,\n",
    "                                value=word_index[\"<PAD>\"],\n",
    "                                padding='post',\n",
    "                                maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLC02j2g-llC"
   },
   "source": [
    "# Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpKOoWgu-llD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chaoyuyang/anaconda3/envs/bentoml-dev/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/chaoyuyang/anaconda3/envs/bentoml-dev/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         128000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 259,713\n",
      "Trainable params: 259,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXSGrjWZ-llW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "WARNING:tensorflow:From /Users/chaoyuyang/anaconda3/envs/bentoml-dev/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "25000/25000 [==============================] - 56s 2ms/sample - loss: 0.5763 - acc: 0.7028 - val_loss: 0.4580 - val_acc: 0.7945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb2a85c5f8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1, # for demo purpose :P\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOMKywn4zReN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 11s 437us/sample - loss: 0.4580 - acc: 0.7945\n",
      "Test score: 0.45802617967128756\n",
      "Test accuracy: 0.79452\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define BentoService for model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting text_classification_service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile text_classification_service.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import sequence, text\n",
    "from bentoml import api, env, BentoService, artifacts\n",
    "from bentoml.artifact import KerasModelArtifact, PickleArtifact\n",
    "from bentoml.handlers import JsonHandler\n",
    "\n",
    "max_features = 1000\n",
    "\n",
    "@artifacts([\n",
    "    KerasModelArtifact('model'),\n",
    "    PickleArtifact('word_index')\n",
    "])\n",
    "@env(pip_dependencies=['tensorflow', 'numpy', 'pandas'])\n",
    "class TextClassificationService(BentoService):\n",
    "   \n",
    "    def word_to_index(self, word):\n",
    "        if word in self.artifacts.word_index and self.artifacts.word_index[word] <= max_features:\n",
    "            return self.artifacts.word_index[word]\n",
    "        else:\n",
    "            return self.artifacts.word_index[\"<UNK>\"]\n",
    "    \n",
    "    def preprocessing(self, text_str):\n",
    "        sequence = text.text_to_word_sequence(text_str)\n",
    "        return list(map(self.word_to_index, sequence))\n",
    "    \n",
    "    @api(JsonHandler)\n",
    "    def predict(self, parsed_json):\n",
    "        if type(parsed_json) == list:\n",
    "            input_data = list(map(self.preprocessing, parsed_json))\n",
    "        else: # expecting type(parsed_json) == dict:\n",
    "            input_data = [self.preprocessing(parsed_json['text'])]\n",
    "\n",
    "        input_data = sequence.pad_sequences(input_data,\n",
    "                                            value=self.artifacts.word_index[\"<PAD>\"],\n",
    "                                            padding='post',\n",
    "                                            maxlen=80)\n",
    "\n",
    "        return self.artifacts.model.predict_classes(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save BentoService to file archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-09-19 15:00:20,515] INFO - Successfully saved Bento 'TextClassificationService:2019_09_19_cbc66362' to path: /Users/chaoyuyang/bentoml/repository/TextClassificationService/2019_09_19_cbc66362\n"
     ]
    }
   ],
   "source": [
    "# 1) import the custom BentoService defined above\n",
    "from text_classification_service import TextClassificationService\n",
    "\n",
    "# 2) `pack` it with required artifacts\n",
    "bento_svc = TextClassificationService.pack(model=model, word_index=word_index)\n",
    "\n",
    "# 3) save your BentoSerivce\n",
    "saved_path = bento_svc.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test packed BentoML service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bento_svc.predict({ 'text': 'bad worst terrible' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bento_svc.predict(['the best movie I have ever seen', 'This is a bad movie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load BentoML Service from archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-09-19 15:00:21,027] WARNING - Module `text_classification_service` already loaded, using existing imported module.\n"
     ]
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "loaded_bento_svc = bentoml.load(saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_bento_svc.predict({ \"text\": \"the best movie I have ever seen\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_bento_svc.predict(['the best movie I have ever seen', 'This is a bad movie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run REST API server locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A saved BentoML service archive can be loaded as a REST API server with bentoml cli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-19 15:12:07.575527: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "WARNING:tensorflow:From /Users/chaoyuyang/anaconda3/envs/bentoml-dev/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/chaoyuyang/anaconda3/envs/bentoml-dev/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/chaoyuyang/anaconda3/envs/bentoml-dev/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      " * Serving Flask app \"TextClassificationService\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [19/Sep/2019 15:12:17] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [19/Sep/2019 15:12:21] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [19/Sep/2019 15:12:23] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [19/Sep/2019 15:12:23] \"\u001b[37mGET /docs.json HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve {saved_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send prediction request to REST API server\n",
    "\n",
    "*Run the following command in terminal to make a HTTP request to the API server*\n",
    "```bash\n",
    "curl -i \\\n",
    "--header \"Content-Type: application/json\" \\\n",
    "--request POST \\\n",
    "--data '{\"text\": \"best movie ever\"}' \\\n",
    "localhost:5000/predict\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"pip install\" a BentoML archive\n",
    "\n",
    "BentoML user can directly pip install saved BentoML archive with `pip install $SAVED_PATH`,  and use it as a regular python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/chaoyuyang/bentoml/repository/TextClassificationService/2019_09_19_cbc66362\n",
      "Building wheels for collected packages: TextClassificationService\n",
      "  Building wheel for TextClassificationService (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /private/var/folders/ns/vc9qhmqx5dx_9fws7d869lqh0000gn/T/pip-ephem-wheel-cache-nnk_qa2n/wheels/2f/77/a3/7ae039c8679d8c3ec4c368d63f070368dd96e19bf3ab69d269\n",
      "Successfully built TextClassificationService\n",
      "Installing collected packages: TextClassificationService\n",
      "  Found existing installation: TextClassificationService 2019-07-16-014454ed\n",
      "    Uninstalling TextClassificationService-2019-07-16-014454ed:\n",
      "      Successfully uninstalled TextClassificationService-2019-07-16-014454ed\n",
      "Successfully installed TextClassificationService-2019-09-19-cbc66362\n"
     ]
    }
   ],
   "source": [
    "!pip install {saved_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-09-19 15:11:46,240] WARNING - Module `text_classification_service` already loaded, using existing imported module.\n",
      "[2019-09-19 15:11:46,465] WARNING - Module `text_classification_service` already loaded, using existing imported module.\n"
     ]
    }
   ],
   "source": [
    "import TextClassificationService\n",
    "\n",
    "installed_svc = TextClassificationService.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installed_svc.predict({ 'text': 'the best movie I have ever seen' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installed_svc.predict({ 'text': 'This is a bad movie' })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI access\n",
    "\n",
    "`pip install $SAVED_PATH` also installs a CLI tool for accessing the BentoML service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: TextClassificationService [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  BentoML CLI tool\r\n",
      "\r\n",
      "Options:\r\n",
      "  -q, --quiet  Hide process logs and only print command results\r\n",
      "  --verbose    Print verbose debugging information for BentoML developer\r\n",
      "  --version    Show the version and exit.\r\n",
      "  --help       Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  <API_NAME>      Run API function\r\n",
      "  info            List APIs\r\n",
      "  open-api-spec   Display OpenAPI/Swagger JSON specs\r\n",
      "  serve           Start local rest server\r\n",
      "  serve-gunicorn  Start local gunicorn server\r\n"
     ]
    }
   ],
   "source": [
    "!TextClassificationService --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print model service information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[39m{\r\n",
      "  \"name\": \"TextClassificationService\",\r\n",
      "  \"version\": \"2019_09_19_cbc66362\",\r\n",
      "  \"created_at\": \"2019-09-19T22:00:20.503864Z\",\r\n",
      "  \"env\": {\r\n",
      "    \"conda_env\": \"name: bentoml-custom-conda-env\\nchannels:\\n- defaults\\ndependencies:\\n- python=3.7.3\\n- pip\\n- pip:\\n  - bentoml[api_server]==0.4.1\\n\",\r\n",
      "    \"pip_dependencies\": \"bentoml==0.4.1\\ntensorflow\\nnumpy\\npandas\"\r\n",
      "  },\r\n",
      "  \"artifacts\": [\r\n",
      "    {\r\n",
      "      \"name\": \"model\",\r\n",
      "      \"artifact_type\": \"KerasModelArtifact\"\r\n",
      "    },\r\n",
      "    {\r\n",
      "      \"name\": \"word_index\",\r\n",
      "      \"artifact_type\": \"PickleArtifact\"\r\n",
      "    }\r\n",
      "  ],\r\n",
      "  \"apis\": [\r\n",
      "    {\r\n",
      "      \"name\": \"predict\",\r\n",
      "      \"handler_type\": \"JsonHandler\",\r\n",
      "      \"docs\": \"BentoML generated API endpoint\"\r\n",
      "    }\r\n",
      "  ]\r\n",
      "}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!TextClassificationService info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 'predict' api with json data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-19 15:11:58.365967: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "WARNING:tensorflow:From /Users/chaoyuyang/anaconda3/envs/bentoml-dev/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/chaoyuyang/anaconda3/envs/bentoml-dev/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/chaoyuyang/anaconda3/envs/bentoml-dev/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "!TextClassificationService predict --input='{\"text\": \"bad movie\"}'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "basic-text-classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
